{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Imports",
   "id": "48550d8c558b58dc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T05:06:19.831886Z",
     "start_time": "2025-01-18T05:06:13.363280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import scipy.io as io\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.signal as signal\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import kurtosis, skew\n",
    "from datetime import datetime\n",
    "import traceback"
   ],
   "id": "71c27a5f8c194768",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Loading Data",
   "id": "914413d57ff2e429"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T05:24:28.704582Z",
     "start_time": "2025-01-18T05:24:08.617556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mat_dir = 'data/' \n",
    "\n",
    "# List mat files in the mat directory that is not label or readme \n",
    "excluded_files = ('label', 'readme', '.')\n",
    "mat_files = [file for file in os.listdir(mat_dir) if not file.startswith(excluded_files)]\n",
    "\n",
    "# Helper function to extract and convert the filenames to float, for easy sorting\n",
    "def extract_numeric_filename(filename):\n",
    "    return float(filename.replace('_','').replace('.mat',''))  # Convert to an integer\n",
    "\n",
    "# Sorting the files based on the numeric value\n",
    "mat_files.sort(key=extract_numeric_filename)\n",
    "\n",
    "# Taking one experiment for each participant\n",
    "seen_prefixes = set()\n",
    "exp_one_files = []\n",
    "exp_one_data = []\n",
    "\n",
    "for file in mat_files:\n",
    "    prefix = file.split('_')[0].strip()\n",
    "    if prefix not in seen_prefixes:\n",
    "        seen_prefixes.add(prefix)\n",
    "        \n",
    "        # Loading the participant file\n",
    "        mat_data = io.loadmat(mat_dir+file) \n",
    "        \n",
    "        # Extracting eeg data for 15 trials\n",
    "        for i in range(1, 16):\n",
    "            key = f'eeg{i}' # since the mat file keys are suffixed by eeg1 to eeg15\n",
    "            # Check for keys with the suffix\n",
    "            for k in mat_data.keys():\n",
    "                if k.endswith(key):\n",
    "                    exp_one_data.append(np.array(mat_data[k]))\n",
    "                    \n",
    "        # Saving the filenames of the files used\n",
    "        exp_one_files.append(file)"
   ],
   "id": "35af4d9e3252f606",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Saving Data to CSV\n",
    "For Fast and Easy loading of datasets"
   ],
   "id": "3975c4238811c0c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T05:24:41.426146Z",
     "start_time": "2025-01-18T05:24:41.394365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_np_to_csv(np_array, name):\n",
    "    \"\"\" Saves numpy array with 3D shape to 2D shape data as csv file, \"\"\"\n",
    "    \n",
    "    reshaped = np_array.reshape(np_array.shape[0] * np_array.shape[1], np_array.shape[2])\n",
    "    print(f'{datetime.now()} : Saving {name}')\n",
    "    np.savetxt(f'{name}.csv', reshaped, delimiter=',')\n",
    "    print(f'{datetime.now()} : Saved {name}')\n",
    "    \n",
    "def save_array_to_csv(array, name):\n",
    "    \"\"\" Saves array with 3D shape to 2D shape data as csv file, \"\"\"\n",
    "    \n",
    "    combined_data = np.vstack(array)\n",
    "    print(f'{datetime.now()} : Saving {name}')\n",
    "    np.savetxt(f'{name}.csv', combined_data, delimiter=',')\n",
    "    print(f'{datetime.now()} : Saved {name}')\n",
    "    \n",
    "def read_csv_to_np(name):\n",
    "    \"\"\" Reads the csv file and changes it to 3D numpy array \"\"\"\n",
    "    \n",
    "    print(f'{datetime.now()} : Reading {name}')\n",
    "    np_data = np.loadtxt(f'{name}.csv', delimiter=',')\n",
    "    reshaped = np_data.reshape(225 ,62, np_data.shape[1])\n",
    "    print(f'{datetime.now()} : Read {name}')\n",
    "    return reshaped\n",
    "\n",
    "def read_csv_to_4d_np(name):\n",
    "    \"\"\" Reads the csv file and changes it to 4D numpy array \"\"\"\n",
    "\n",
    "    print('{} : Reading 4D numpy {}'.format(datetime.now(), name))\n",
    "    reshaped = []\n",
    "    try:\n",
    "        np_data = np.loadtxt('{}.csv'.format(name), delimiter=',')\n",
    "        print('{} : Shape {}'.format(datetime.now(), np_data.shape))\n",
    "        reshaped = np_data.reshape(np_data.shape[1], 4, 62, np_data.shape[0] // 248)\n",
    "        print('{} : Read 4D numpy {}'.format(datetime.now(), name))\n",
    "    except Exception as e:\n",
    "        print('{} : Error reading 4D numpy: {}'.format(datetime.now(), e))\n",
    "        traceback.print_exc()\n",
    "    return reshaped\n",
    "\n",
    "def save_4d_np_to_csv(np_array, name):\n",
    "    \"\"\" Saves numpy array with 4D shape to 2D shape data as csv file, ()\"\"\"\n",
    "    \n",
    "    reshaped = np_array.reshape(np_array.shape[1] * np_array.shape[2] * np_array.shape[3], np_array.shape[0])\n",
    "    print('{} : Saving 4D numpy {}'.format(datetime.now(), name))\n",
    "    np.savetxt('{}.csv'.format(name), reshaped, delimiter=',')\n",
    "    print('{} : Saved 4D numpy {}'.format(datetime.now(), name))\n",
    "\n"
   ],
   "id": "bff5a84957b12927",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Plotting the Data",
   "id": "9105a52a4779c2e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Padding the datapoints\n",
    "Since the datapoints number varies for different channels, I decided to add paading to the short channels for easy plotting"
   ],
   "id": "1c123143dfa9176"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T05:26:21.266032Z",
     "start_time": "2025-01-18T05:24:52.073013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "max_length = 0\n",
    "for trial in exp_one_data:\n",
    "    max_length = max(max_length, trial.shape[1])\n",
    "\n",
    "exp_one_data_padded = []\n",
    "for trial in exp_one_data:\n",
    "    padded_data = np.pad(trial, ((0, 0), (0, max_length - trial.shape[1])), mode='constant', constant_values=0)\n",
    "    exp_one_data_padded.append(padded_data)\n",
    "\n",
    "exp_one_data_padded_np =  np.array(exp_one_data_padded)\n",
    "print(exp_one_data_padded_np.shape)\n",
    "#save_np_to_csv(exp_one_data_padded_np, 'exp_one_data_padded_np')\n",
    "\n",
    "# Printing the first and second sample\n",
    "print(f'Sample 1 shape : {exp_one_data_padded[0].shape}')\n",
    "print(f'Sample 2 shape : {exp_one_data_padded[1].shape}')"
   ],
   "id": "483e82b7a966f9ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225, 62, 53001)\n",
      "Sample 1 shape : (62, 53001)\n",
      "Sample 2 shape : (62, 53001)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Plotting for channel 1",
   "id": "4f867ffaa88f3ddb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Assuming `data` is your EEG data with shape (trials, channels, time_points)\n",
    "def plot_eeg(data, title):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(data.T)  # Plotting the first channel\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Time Points')\n",
    "    plt.ylabel('Voltage (ÂµV)')\n",
    "    plt.savefig(f'{title}.png')\n",
    "    plt.show()\n"
   ],
   "id": "4ccbadb5cae5a58b",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#exp_one_data_padded_np = read_csv_to_np('exp_one_data_padded_np')\n",
    "print(f'{datetime.now()} : Plotting  exp_one_data_padded_np')\n",
    "plot_eeg(exp_one_data_padded_np[:,0,:], 'EEG Data for Channel 1')\n",
    "print(f'{datetime.now()} : Plotted  exp_one_data_padded_np')"
   ],
   "id": "a905f75d540d37b4",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Butterworth Band-pass filter",
   "id": "7e45be34e418e169"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define the sampling frequency (in Hz) and the EEG data\n",
    "Fs = 200\n",
    " \n",
    "# Define frequency bands\n",
    "bands = {\n",
    "    'Alpha': (1, 7),\n",
    "    'Beta': (8, 13),\n",
    "    'Theta': (14, 30),\n",
    "    'Gamma': (30, 45)\n",
    "}\n",
    "\n",
    "# Butterworth bandpass filter function\n",
    "def butter_bandpass(lowcut, highcut, Fs, order=4):\n",
    "    nyquist = 0.5 * Fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = signal.butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "# Function to apply the filter\n",
    "def apply_filter(data, lowcut, highcut, Fs, order=4):\n",
    "    b, a = butter_bandpass(lowcut, highcut, Fs, order)\n",
    "    y = signal.filtfilt(b, a, data, axis=0)\n",
    "    return y\n",
    "\n",
    "# Apply filters to each band, trial, and channel (accounting for variable datapoint lengths)\n",
    "filtered_data = {band: [] for band in bands}\n",
    "\n",
    "for band, (lowcut, highcut) in bands.items():\n",
    "    j = 1\n",
    "    for trial_data in exp_one_data_padded_np:\n",
    "        j=j+1\n",
    "        trial_filtered = []\n",
    "        i = 1\n",
    "        for channel_data in trial_data:\n",
    "            print(f'Processing {band} Band, trial {j} - channel {i} .....')\n",
    "            i=i+1\n",
    "            filtered_channel = apply_filter(channel_data, lowcut, highcut, Fs)\n",
    "            trial_filtered.append(filtered_channel)\n",
    "        trial_filtered_np = np.array(trial_filtered)\n",
    "        filtered_data[band].append(trial_filtered_np)  # Store filtered trial"
   ],
   "id": "19c2c55025f2330f",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for band, trials in filtered_data.items():\n",
    "    save_array_to_csv(trials, f'{band}')"
   ],
   "id": "631b6fe16f524734",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Plotting Bands",
   "id": "fae543e953b4adfb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "alpha_np = read_csv_to_np('Alpha')\n",
    "plot_eeg(alpha_np[:,0,:], f'EEG Data for Alpha Band Channel 1')"
   ],
   "id": "7c986df6d863960a",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "beta_np = read_csv_to_np('Beta')\n",
    "plot_eeg(beta_np[:,0,:], f'EEG Data for Beta Band Channel 1')"
   ],
   "id": "b4630aee8a17f39b",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "theta_np = read_csv_to_np('Theta')\n",
    "plot_eeg(theta_np[:,0,:], f'EEG Data for Theta Band Channel 1')"
   ],
   "id": "fbdffc3fb1871c58",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gamma_np = read_csv_to_np('Gamma')\n",
    "plot_eeg(gamma_np[:,0,:], f'EEG Data for Gamma Band Channel 1')"
   ],
   "id": "66bbdeadcc8adbf2",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Taking only 80s\n",
    "Due to different data lengths of different channels for different samples, we take only the first 80s of the data\n",
    "\n",
    "**80s = 200 * 80 = 16,000 data points**"
   ],
   "id": "a73789dadb8b7e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "alpha_np_80s = alpha_np[:,:,:16000]\n",
    "beta_np_80s = beta_np[:,:,:16000]\n",
    "theta_np_80s = theta_np[:,:,:16000]\n",
    "gamma_np_80s = gamma_np[:,:,:16000]\n",
    "\n",
    "print(f'Alpha {alpha_np_80s.shape}, Beta {beta_np_80s.shape}, Theta {theta_np_80s.shape}, Gamma {gamma_np_80s.shape}')\n",
    "    "
   ],
   "id": "79fcbb486f760087",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sliding Windows and Feature Matrices",
   "id": "3e123f26cb08a9a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Function to create sliding windows\n",
    "def create_feature_matrix(data, window_size, stride):\n",
    "    windows = []\n",
    "    pcc_matrices = []\n",
    "    mean_features = []\n",
    "    variance_features = []\n",
    "    kurtosis_features = []\n",
    "    skewness_features = []\n",
    "\n",
    "    # Loop over each trial\n",
    "    for trial_data in data:\n",
    "        # Loop through the data with the sliding window\n",
    "        for start in range(0, trial_data.shape[1] - window_size + 1, stride):\n",
    "            end = start + window_size\n",
    "            # Extract the window\n",
    "            window = trial_data[:, start:end]\n",
    "            windows.append(window)\n",
    "\n",
    "            #Extracting PCC features\n",
    "            pcc_matrices.append(np.corrcoef(window))\n",
    "\n",
    "            # Extracting statistical features across samples for each channel\n",
    "            mean_val = np.mean(window, axis=1)\n",
    "            mean_features.append(mean_val)\n",
    "\n",
    "            variance_val = np.var(window, axis=1)\n",
    "            variance_features.append(variance_val)\n",
    "\n",
    "            kurtosis_val = kurtosis(window, axis=1)\n",
    "            kurtosis_features.append(kurtosis_val)\n",
    "\n",
    "            skewness_val = skew(window, axis=1)\n",
    "            skewness_features.append(skewness_val)\n",
    "\n",
    "    sc_matrix = np.stack((np.array(mean_features), np.array(variance_features), np.array(kurtosis_features),\n",
    "                          np.array(skewness_features)), axis=2)\n",
    "    return np.array(windows), np.array(pcc_matrices), sc_matrix\n",
    "\n",
    "\n",
    "# Define time window sizes and strides\n",
    "window_size_8s = 1600  # 8 seconds -> (16000 / 80) * 8 -> 1600 time steps\n",
    "stride_4s = 800  # 4 seconds -> 800 time steps\n",
    "\n",
    "window_size_12s = 2400  # 12 seconds -> 2400 time steps\n",
    "stride_8s = 1600  # 8 seconds -> 1600 time steps\n",
    "\n",
    "# Create Alpha feature matrices\n",
    "print('{} : Creating Alpha Feature Matrices'.format(datetime.now()))\n",
    "alpha_window_matrix_8s, alpha_pcc_matrix_8s, alpha_sc_matrix_8s = create_feature_matrix(\n",
    "    alpha_np_80s, window_size_8s,\n",
    "    stride_4s)\n",
    "alpha_window_matrix_12s, alpha_pcc_matrix_12s, alpha_sc_matrix_12s = create_feature_matrix(\n",
    "    alpha_np_80s, window_size_12s,\n",
    "    stride_8s)\n",
    "print('{} : Created Alpha Feature Matrices'.format(datetime.now()))\n",
    "\n",
    "# Create Beta feature matrices\n",
    "print('{} : Creating Beta Feature Matrices'.format(datetime.now()))\n",
    "beta_window_matrix_8s, beta_pcc_matrix_8s, beta_sc_matrix_8s = create_feature_matrix(beta_np_80s, window_size_8s,\n",
    "                                                                                     stride_4s)\n",
    "beta_window_matrix_12s, beta_pcc_matrix_12s, beta_sc_matrix_12s = create_feature_matrix(beta_np_80s, window_size_12s,\n",
    "                                                                                        stride_8s)\n",
    "print('{} : Created Beta Feature Matrices'.format(datetime.now()))\n",
    "\n",
    "# Create Theta feature matrices\n",
    "print('{} : Creating Theta Feature Matrices'.format(datetime.now()))\n",
    "theta_window_matrix_8s, theta_pcc_matrix_8s, theta_sc_matrix_8s = create_feature_matrix(\n",
    "    theta_np_80s, window_size_8s,\n",
    "    stride_4s)\n",
    "theta_window_matrix_12s, theta_pcc_matrix_12s, theta_sc_matrix_12s = create_feature_matrix(\n",
    "    theta_np_80s, window_size_12s,\n",
    "    stride_8s)\n",
    "print('{} : Created Theta Feature Matrices'.format(datetime.now()))\n",
    "\n",
    "# Create Gamma feature matrices\n",
    "print('{} : Creating Gamma Feature Matrices'.format(datetime.now()))\n",
    "gamma_window_matrix_8s, gamma_pcc_matrix_8s, gamma_sc_matrix_8s = create_feature_matrix(\n",
    "    gamma_np_80s, window_size_8s,\n",
    "    stride_4s)\n",
    "gamma_window_matrix_12s, gamma_pcc_matrix_12s, gamma_sc_matrix_12s = create_feature_matrix(\n",
    "    gamma_np_80s, window_size_12s,\n",
    "    stride_8s)\n",
    "print('{} : Created Gamma Feature Matrices'.format(datetime.now()))\n",
    "\n",
    "# Combining the four bands\n",
    "window_matrix_8s = np.stack((alpha_window_matrix_8s, beta_window_matrix_8s, theta_window_matrix_8s,\n",
    "                             gamma_window_matrix_8s), axis=1)\n",
    "window_matrix_12s = np.stack((alpha_window_matrix_12s, beta_window_matrix_12s, theta_window_matrix_12s,\n",
    "                              gamma_window_matrix_12s), axis=1)\n",
    "pcc_matrix_8s = np.stack((alpha_pcc_matrix_8s, beta_pcc_matrix_8s, theta_pcc_matrix_8s, gamma_pcc_matrix_8s), axis=1)\n",
    "pcc_matrix_12s = np.stack((alpha_pcc_matrix_12s, beta_pcc_matrix_12s, theta_pcc_matrix_12s, gamma_pcc_matrix_12s),\n",
    "                          axis=1)\n",
    "\n",
    "sc_matrix_8s = np.stack((alpha_sc_matrix_8s, beta_sc_matrix_8s, theta_sc_matrix_8s, gamma_sc_matrix_8s), axis=1)\n",
    "sc_matrix_12s = np.stack((alpha_sc_matrix_12s, beta_sc_matrix_12s, theta_sc_matrix_12s, gamma_sc_matrix_12s), axis=1)"
   ],
   "id": "cd7db845709e8333",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Saving feature matrices\n",
    "save_4d_np_to_csv(window_matrix_8s, 'windows_matrix_8s')\n",
    "save_4d_np_to_csv(window_matrix_12s, 'windows_matrix_12s')\n",
    "save_4d_np_to_csv(pcc_matrix_8s, 'pcc_matrix_8s')\n",
    "save_4d_np_to_csv(pcc_matrix_12s, 'pcc_matrix_12s')\n",
    "save_4d_np_to_csv(sc_matrix_8s, 'sc_matrix_8s')\n",
    "save_4d_np_to_csv(sc_matrix_12s, 'sc_matrix_12s')\n",
    "\n",
    "# Output feature matrix shapes\n",
    "print(\"Window matrix (8s window, 4s stride):\", window_matrix_8s.shape)\n",
    "print(\"window matrix (12s window, 8s stride):\", window_matrix_12s.shape)\n",
    "\n",
    "print(\"PCC Feature matrix (8s window, 4s stride):\", pcc_matrix_8s.shape)\n",
    "print(\"PCC Feature matrix (12s window, 8s stride):\", pcc_matrix_12s.shape)\n",
    "\n",
    "print(\"SC Feature matrix (8s window, 4s stride):\", sc_matrix_8s.shape)\n",
    "print(\"SC Feature matrix (12s window, 8s stride):\", sc_matrix_12s.shape)"
   ],
   "id": "d54b1f52b9c2f928",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### PCA",
   "id": "4e10b14b330c9a0c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "window_matrix_12s = read_csv_to_4d_np('windows_matrix_12s')\n",
    "window_matrix_8s = read_csv_to_4d_np('windows_matrix_8s')\n",
    "\n",
    "def get_pca_features(data):\n",
    "    print('{} : Creating PCA Feature Matrices'.format(datetime.now()))\n",
    "    # We need to reshape data so that time points are processed correctly.\n",
    "    # Let's combine windows, bands, and channels, leaving the temporal dimension intact.\n",
    "\n",
    "    # Flatten segments, bands, and channels together: (segments * bands * channels, datapoints)\n",
    "    reshaped_data = data.reshape(-1, data.shape[3])\n",
    "\n",
    "    # Apply PCA on temporal dimension (2400 datapoints)\n",
    "    n_components_time = 62  # Desired number of components\n",
    "    pca = PCA(n_components=n_components_time)\n",
    "\n",
    "    # Apply PCA\n",
    "    print('{} : Applying PCA ...'.format(datetime.now()))\n",
    "    pca_result = pca.fit_transform(reshaped_data)\n",
    "\n",
    "    # Reshape back to original dimensionality without temporal reduction: (segments, 4, 62, n_components_time)\n",
    "    pca_matrix = pca_result.reshape(data.shape[0], 4, 62, n_components_time)\n",
    "\n",
    "    print('{} : Created PCA Feature Matrices, Shape {}'.format(datetime.now(), pca_matrix.shape))\n",
    "    return pca_matrix\n",
    "pca_matrix_8s = get_pca_features(window_matrix_8s)\n",
    "pca_matrix_12s = get_pca_features(window_matrix_12s)\n",
    "\n",
    "print(\"PCA Feature matrix (8s window, 4s stride):\", pca_matrix_8s.shape)\n",
    "print(\"PCA Feature matrix (12s window, 8s stride):\", pca_matrix_12s.shape)\n",
    "\n",
    "save_4d_np_to_csv(pca_matrix_8s, 'pca_matrix_8s')\n",
    "save_4d_np_to_csv(pca_matrix_12s, 'pca_matrix_12s')\n",
    "\n",
    "print(\"********************** {} : FINISHED *********************\".format(datetime.now()))"
   ],
   "id": "b2d1d496a1e20c03",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
